{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ritikseptember2003/Improved-YOLOv8_Foggy_Image_Object_Detection/blob/dev/Improved_YOLOv8_Foggy_Image_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEy1tHZoYyNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77519fda-7668-403c-8cf5-60d06424c803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics torch torchvision torchaudio --quiet\n",
        "!pip install opencv-python albumentations timm tqdm --quiet\n",
        "!pip install onnx onnxruntime --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6p0PYRtaTp_",
        "outputId": "d6a0fddc-a8d0-4976-ded5-f8e331ee3cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 installed successfully!\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "!git clone https://github.com/ultralytics/ultralytics.git\n",
        "%cd ultralytics\n",
        "!pip install -e .\n",
        "clear_output()\n",
        "print(\"YOLOv8 installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J51upYBIafXd",
        "outputId": "e6fbd5a2-e9d3-4088-bd0b-b1e44fa66ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch Version: 2.6.0+cu124\n",
            "CUDA Available: True\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Torch Version:\", torch.__version__)\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU Found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8RRC1-ftPdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae8cbde-99a5-4f82-d980-7b156576cfd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMDEAUyiuKp1"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/RTTS.zip /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwLq0ZF_uVf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f8a8ff-6cc0-49fb-c75a-e7823e20f6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset successfully extracted to /content/datasets/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/RTTS.zip\"\n",
        "extract_path = \"/content/datasets\"\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset successfully extracted to /content/datasets/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj_CcN_suyFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae3f7b96-3c20-4914-ac63-76e665e72ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations  ImageSets\tJPEGImages\n"
          ]
        }
      ],
      "source": [
        "!ls /content/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khccZtkdwcTl"
      },
      "outputs": [],
      "source": [
        "!pip install lxml tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tSx4DcExnid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4a1aca-06e3-445c-e290-a0aa82e86bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO labels directory created!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "yolo_labels_path = \"/content/datasets/labels\"\n",
        "os.makedirs(yolo_labels_path, exist_ok=True)\n",
        "os.makedirs(f\"{yolo_labels_path}/train\", exist_ok=True)\n",
        "os.makedirs(f\"{yolo_labels_path}/val\", exist_ok=True)\n",
        "os.makedirs(f\"{yolo_labels_path}/test\", exist_ok=True)\n",
        "\n",
        "print(\"YOLO labels directory created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OygOANpyHV2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9711d054-7adf-4557-8b8e-e5122d16c766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations  ImageSets\tJPEGImages  labels\n"
          ]
        }
      ],
      "source": [
        "!ls /content/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7I4InFmxshW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0f54d7-4e3a-430a-a8a2-06683f1a7684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting Annotations: 100%|██████████| 4322/4322 [00:01<00:00, 3169.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 4322 XML annotations to YOLO format!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define paths\n",
        "voc_annotations_path = \"/content/datasets/Annotations\"\n",
        "yolo_labels_path = \"/content/datasets/labels/train\"\n",
        "\n",
        "# Define class names (same as the research paper)\n",
        "class_names = [\"car\", \"bus\", \"person\", \"bicycle\", \"motorbike\"]\n",
        "\n",
        "# Function to convert XML to YOLO format\n",
        "def convert_voc_to_yolo(xml_file, output_txt_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    img_width = int(root.find(\"size/width\").text)\n",
        "    img_height = int(root.find(\"size/height\").text)\n",
        "\n",
        "    with open(output_txt_file, \"w\") as f:\n",
        "        for obj in root.findall(\"object\"):\n",
        "            class_name = obj.find(\"name\").text\n",
        "            if class_name not in class_names:\n",
        "                continue  # Skip unknown classes\n",
        "\n",
        "            class_id = class_names.index(class_name)\n",
        "            bbox = obj.find(\"bndbox\")\n",
        "            xmin = int(bbox.find(\"xmin\").text)\n",
        "            ymin = int(bbox.find(\"ymin\").text)\n",
        "            xmax = int(bbox.find(\"xmax\").text)\n",
        "            ymax = int(bbox.find(\"ymax\").text)\n",
        "\n",
        "            # Convert to YOLO format (normalized)\n",
        "            x_center = ((xmin + xmax) / 2) / img_width\n",
        "            y_center = ((ymin + ymax) / 2) / img_height\n",
        "            width = (xmax - xmin) / img_width\n",
        "            height = (ymax - ymin) / img_height\n",
        "\n",
        "            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "# Convert all XML files\n",
        "xml_files = glob.glob(f\"{voc_annotations_path}/*.xml\")\n",
        "for xml_file in tqdm(xml_files, desc=\"Converting Annotations\"):\n",
        "    output_txt_file = f\"{yolo_labels_path}/{os.path.basename(xml_file).replace('.xml', '.txt')}\"\n",
        "    convert_voc_to_yolo(xml_file, output_txt_file)\n",
        "\n",
        "print(f\"Converted {len(xml_files)} XML annotations to YOLO format!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoJOrTMOHbDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2885ad9-87f8-4001-b4c6-36af31a9c586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  val\n"
          ]
        }
      ],
      "source": [
        "!ls /content/datasets/labels/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIoy19OpxzuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5406cbe-2b60-4769-84d8-f697c82be67a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AM_Bing_211.txt\n",
            "AM_Bing_217.txt\n",
            "AM_Bing_222.txt\n",
            "AM_Bing_229.txt\n",
            "AM_Bing_232.txt\n",
            "AM_Bing_242.txt\n",
            "AM_Bing_243.txt\n",
            "AM_Bing_274.txt\n",
            "AM_Bing_318.txt\n",
            "AM_Bing_422.txt\n"
          ]
        }
      ],
      "source": [
        "!ls /content/datasets/labels/train | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tdHabnAywYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af437917-52c8-480f-9ccf-496d0df99276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created Train, Validation, and Test folders!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define dataset directories\n",
        "split_dirs = [\"train\", \"val\", \"test\"]\n",
        "for split in split_dirs:\n",
        "    os.makedirs(f\"/content/datasets/images/{split}\", exist_ok=True)\n",
        "    os.makedirs(f\"/content/datasets/labels/{split}\", exist_ok=True)\n",
        "\n",
        "print(\"Created Train, Validation, and Test folders!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnwJHACwH2BZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d947ae4-4180-42a8-ef97-1fecd5877a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations  images  ImageSets\tJPEGImages  labels\n"
          ]
        }
      ],
      "source": [
        "!ls /content/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NKKdEbaH-JG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c407d61-88f1-4113-c560-36bdeaa248c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  val\n"
          ]
        }
      ],
      "source": [
        "!ls /content/datasets/images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igQ6AHku2d6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41581d73-4325-47ef-be78-ad1043668bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AM_Bing_211.png\n",
            "AM_Bing_217.png\n",
            "AM_Bing_222.png\n",
            "AM_Bing_229.png\n",
            "AM_Bing_232.png\n",
            "AM_Bing_242.png\n",
            "AM_Bing_243.png\n",
            "AM_Bing_274.png\n",
            "AM_Bing_318.png\n",
            "AM_Bing_422.png\n"
          ]
        }
      ],
      "source": [
        "!ls /content/datasets/JPEGImages | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bVIA5xR2fq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c51a31-73db-4625-b075-e183e4267cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image directory found: /content/datasets/JPEGImages\n",
            "✅ Found 4322 images\n",
            "Fixed Dataset Split: 3457 Train, 432 Val, 433 Test\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Update image directory path\n",
        "image_dir = \"/content/datasets/JPEGImages\"  # Confirm this is correct\n",
        "label_dir = \"/content/datasets/labels/train\"\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(image_dir):\n",
        "    print(f\"ERROR: Image directory {image_dir} not found!\")\n",
        "else:\n",
        "    print(f\"Image directory found: {image_dir}\")\n",
        "\n",
        "# Get all PNG images\n",
        "image_files = glob.glob(f\"{image_dir}/*.png\")  # Updated for PNG files\n",
        "if len(image_files) == 0:\n",
        "    print(\"No images found in directory!\")\n",
        "else:\n",
        "    print(f\"✅ Found {len(image_files)} images\")\n",
        "\n",
        "# Shuffle dataset randomly\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio, val_ratio = 0.8, 0.1\n",
        "train_split = int(len(image_files) * train_ratio)\n",
        "val_split = int(len(image_files) * (train_ratio + val_ratio))\n",
        "\n",
        "# Split dataset\n",
        "train_files = image_files[:train_split]\n",
        "val_files = image_files[train_split:val_split]\n",
        "test_files = image_files[val_split:]\n",
        "\n",
        "# Function to move images & labels\n",
        "def move_files(files, split):\n",
        "    for file in files:\n",
        "        file_name = os.path.basename(file)\n",
        "        img_dest = f\"/content/datasets/images/{split}/{file_name}\"\n",
        "        label_file = f\"{label_dir}/{file_name.replace('.png', '.txt')}\"  # 🔹 Updated for PNG\n",
        "\n",
        "        # Move image\n",
        "        if os.path.exists(file):\n",
        "            shutil.move(file, img_dest)\n",
        "\n",
        "        # Move corresponding label\n",
        "        if os.path.exists(label_file):\n",
        "            shutil.move(label_file, f\"/content/datasets/labels/{split}/{file_name.replace('.png', '.txt')}\")\n",
        "\n",
        "# Move images & labels into correct folders\n",
        "move_files(train_files, \"train\")\n",
        "move_files(val_files, \"val\")\n",
        "move_files(test_files, \"test\")\n",
        "\n",
        "print(f\"Fixed Dataset Split: {len(train_files)} Train, {len(val_files)} Val, {len(test_files)} Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GDdAQc22unM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5efc619b-dabd-4b3e-e85b-267896af52ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: 3457\n",
            "Validation Images: 432\n",
            "Test Images: 433\n",
            "Train Labels: 3457\n",
            "Validation Labels: 432\n",
            "Test Labels: 433\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Images:\", len(os.listdir(\"/content/datasets/images/train\")))\n",
        "print(\"Validation Images:\", len(os.listdir(\"/content/datasets/images/val\")))\n",
        "print(\"Test Images:\", len(os.listdir(\"/content/datasets/images/test\")))\n",
        "\n",
        "print(\"Train Labels:\", len(os.listdir(\"/content/datasets/labels/train\")))\n",
        "print(\"Validation Labels:\", len(os.listdir(\"/content/datasets/labels/val\")))\n",
        "print(\"Test Labels:\", len(os.listdir(\"/content/datasets/labels/test\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWVeXqL428Sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d6eb2e-a414-4b43-aa8a-51f09f4fdabe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 dataset configuration file `data.yaml` created!\n"
          ]
        }
      ],
      "source": [
        "yaml_content = \"\"\"\n",
        "train: /content/datasets/images/train\n",
        "val: /content/datasets/images/val\n",
        "test: /content/datasets/images/test\n",
        "\n",
        "nc: 5  # Number of classes\n",
        "names: [\"car\", \"bus\", \"person\", \"bicycle\", \"motorbike\"]\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/datasets/data.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"YOLOv8 dataset configuration file `data.yaml` created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdk9cDfdXP2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb69d64-c42c-426c-f997-ba5fd74abc7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train: /content/datasets/images/train\n",
            "val: /content/datasets/images/val\n",
            "test: /content/datasets/images/test\n",
            "\n",
            "nc: 5  # Number of classes\n",
            "names: [\"car\", \"bus\", \"person\", \"bicycle\", \"motorbike\"]\n"
          ]
        }
      ],
      "source": [
        "!cat /content/datasets/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NwmWTRA3snZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778a56bc-2890-4f3a-9efe-13177e40d9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: ultralytics 8.3.92\n",
            "Uninstalling ultralytics-8.3.92:\n",
            "  Successfully uninstalled ultralytics-8.3.92\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall ultralytics -y\n",
        "!pip install ultralytics --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"✅ YOLOv8 Imported Successfully!\")"
      ],
      "metadata": {
        "id": "gohpftXkXMHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3718eead-6250-470d-ebc3-17902dde7b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ YOLOv8 Imported Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egvaXIZ94MEP"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26c9gIFm40Yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13093849-a11e-4404-d162-d576f13cc958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n",
            "100% 21.5M/21.5M [00:00<00:00, 168MB/s]\n",
            "Ultralytics 8.3.92 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 18.0MB/s]\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742326364.888849    2850 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742326364.971641    2850 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2117983  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,137,535 parameters, 11,137,519 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 83.4MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/labels/train... 3457 images, 0 backgrounds, 2 corrupt: 100% 3457/3457 [00:02<00:00, 1225.71it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/images/train/hv2_10.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1026]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/images/train/hv2_16.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0972]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/labels/val... 432 images, 0 backgrounds, 0 corrupt: 100% 432/432 [00:00<00:00, 757.22it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/labels/val.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/5      5.15G      1.212      1.177      1.119        268        640: 100% 216/216 [01:35<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 14/14 [00:08<00:00,  1.71it/s]\n",
            "                   all        432       4354      0.677      0.519      0.568      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/5      5.19G      1.208     0.9569      1.124        148        640: 100% 216/216 [01:29<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 14/14 [00:07<00:00,  1.96it/s]\n",
            "                   all        432       4354       0.71      0.493      0.576      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/5      5.23G      1.188     0.9077       1.12        287        640: 100% 216/216 [01:29<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 14/14 [00:07<00:00,  1.94it/s]\n",
            "                   all        432       4354      0.692      0.537      0.612      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        4/5      5.26G      1.145     0.8493      1.095        176        640: 100% 216/216 [01:30<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 14/14 [00:06<00:00,  2.22it/s]\n",
            "                   all        432       4354      0.719      0.625      0.673      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        5/5       5.3G      1.086     0.7672      1.067        303        640: 100% 216/216 [01:32<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 14/14 [00:05<00:00,  2.59it/s]\n",
            "                   all        432       4354      0.723      0.625       0.69      0.451\n",
            "\n",
            "5 epochs completed in 0.139 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.92 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,127,519 parameters, 0 gradients, 28.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 14/14 [00:09<00:00,  1.50it/s]\n",
            "                   all        432       4354      0.723      0.625       0.69      0.451\n",
            "                   car        313       2702      0.757      0.825      0.866      0.594\n",
            "                   bus        125        292      0.516      0.627      0.586      0.383\n",
            "                person        264       1136      0.861      0.701      0.808      0.526\n",
            "               bicycle         45         81      0.666       0.54      0.586      0.393\n",
            "             motorbike         66        143      0.815      0.431      0.606      0.359\n",
            "Speed: 0.3ms preprocess, 3.3ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train model=yolov8s.pt data=/content/datasets/data.yaml epochs=5 imgsz=640 batch=16 device=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gexh1adZoii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6726a0a2-41a7-413f-f271-5dd963b5f26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained YOLOv8 model saved as `best_model.pt`\n"
          ]
        }
      ],
      "source": [
        "!cp runs/detect/train/weights/best.pt /content/best_model.pt\n",
        "print(\"Trained YOLOv8 model saved as `best_model.pt`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar1awC96KZhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d1c7e0-31cb-4bcf-e1ba-55ada1bb3344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 129 layers, 11,137,535 parameters, 0 gradients, 28.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 11137535, 0, 28.6555648)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your trained model\n",
        "model = YOLO(\"/content/best_model.pt\")\n",
        "\n",
        "# Print model summary\n",
        "model.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k483rs3C07Qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fafd4dc-76b2-4f35-a1bf-46274eb12b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.92 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,127,519 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/labels/val.cache... 432 images, 0 backgrounds, 0 corrupt: 100% 432/432 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 27/27 [00:10<00:00,  2.47it/s]\n",
            "                   all        432       4354      0.754      0.594      0.689       0.45\n",
            "                   car        313       2702      0.811      0.794      0.867      0.594\n",
            "                   bus        125        292       0.55      0.586      0.579      0.381\n",
            "                person        264       1136      0.884      0.673      0.808      0.529\n",
            "               bicycle         45         81        0.7      0.519      0.581      0.384\n",
            "             motorbike         66        143      0.826      0.399      0.612      0.363\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=val model=/content/best_model.pt data=/content/datasets/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDsPVdGaeHQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f63e5ae4-4269-474b-b197-7af040509c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Try loading the trained model\n",
        "try:\n",
        "    model = YOLO(\"/content/best_model.pt\")\n",
        "    print(\"Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading model:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0V7kR_9Wb8u",
        "outputId": "45422cd1-400b-40d7-8068-1d2b03be2a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 129 layers, 11,137,535 parameters, 0 gradients, 28.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 11137535, 0, 28.6555648)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJP7jzRLeLBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1668525a-aefb-40f8-a89f-c49f2b9ee85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AM_Bing_211.png\n",
            "AM_Google_250.png\n",
            "BD_Baidu_105.png\n",
            "BD_Baidu_117.png\n",
            "BD_Baidu_199.png\n",
            "BD_Baidu_211.png\n",
            "BD_Baidu_284.png\n",
            "BD_Baidu_461.png\n",
            "BD_Baidu_476.png\n",
            "BD_Baidu_486.png\n"
          ]
        }
      ],
      "source": [
        "!ls /content/datasets/images/test/ | head -10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/runs/detect/*  # Deletes old predictions\n",
        "!yolo task=detect mode=predict model=/content/best_model.pt \\\n",
        "      source=/content/datasets/images/test save=True \\\n",
        "      project=/content/runs name=detect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAIWwetiZsU1",
        "outputId": "27208431-c3ef-4eea-f94e-90cb56810a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.92 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,127,519 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\n",
            "image 1/433 /content/datasets/images/test/AM_Bing_211.png: 384x640 2 persons, 42.1ms\n",
            "image 2/433 /content/datasets/images/test/AM_Google_250.png: 448x640 4 persons, 41.3ms\n",
            "image 3/433 /content/datasets/images/test/BD_Baidu_105.png: 480x640 4 cars, 2 buss, 40.5ms\n",
            "image 4/433 /content/datasets/images/test/BD_Baidu_117.png: 288x640 4 cars, 1 bus, 1 person, 1 bicycle, 40.2ms\n",
            "image 5/433 /content/datasets/images/test/BD_Baidu_199.png: 512x640 2 persons, 45.9ms\n",
            "image 6/433 /content/datasets/images/test/BD_Baidu_211.png: 480x640 2 cars, 13.8ms\n",
            "image 7/433 /content/datasets/images/test/BD_Baidu_284.png: 640x640 3 persons, 1 bicycle, 2 motorbikes, 16.9ms\n",
            "image 8/433 /content/datasets/images/test/BD_Baidu_461.png: 512x640 16 cars, 13.8ms\n",
            "image 9/433 /content/datasets/images/test/BD_Baidu_476.png: 384x640 8 persons, 11.3ms\n",
            "image 10/433 /content/datasets/images/test/BD_Baidu_486.png: 448x640 5 persons, 4 motorbikes, 13.6ms\n",
            "image 11/433 /content/datasets/images/test/BD_Bing_084.png: 544x640 1 car, 1 person, 1 motorbike, 40.2ms\n",
            "image 12/433 /content/datasets/images/test/BD_Bing_423.png: 416x640 3 cars, 1 bus, 1 person, 40.8ms\n",
            "image 13/433 /content/datasets/images/test/BD_Bing_463.png: 448x640 1 person, 1 bicycle, 1 motorbike, 13.4ms\n",
            "image 14/433 /content/datasets/images/test/BD_Bing_634.png: 448x640 4 cars, 10 persons, 4 bicycles, 3 motorbikes, 12.7ms\n",
            "image 15/433 /content/datasets/images/test/BD_Bing_643.png: 448x640 1 car, 4 persons, 1 bicycle, 2 motorbikes, 12.7ms\n",
            "image 16/433 /content/datasets/images/test/BD_Google_098.png: 416x640 7 persons, 13.1ms\n",
            "image 17/433 /content/datasets/images/test/BD_Google_129.png: 640x480 1 person, 39.6ms\n",
            "image 18/433 /content/datasets/images/test/BD_Google_378.png: 448x640 1 bus, 19 persons, 13.3ms\n",
            "image 19/433 /content/datasets/images/test/BD_Google_501.png: 224x640 1 car, 1 bus, 1 person, 39.9ms\n",
            "image 20/433 /content/datasets/images/test/BJ_Baidu_015.png: 384x640 27 cars, 1 bus, 11.2ms\n",
            "image 21/433 /content/datasets/images/test/BJ_Baidu_1132.png: 448x640 4 persons, 13.3ms\n",
            "image 22/433 /content/datasets/images/test/BJ_Baidu_1269.png: 448x640 2 persons, 12.7ms\n",
            "image 23/433 /content/datasets/images/test/BJ_Baidu_199.png: 480x640 7 cars, 1 person, 13.4ms\n",
            "image 24/433 /content/datasets/images/test/BJ_Baidu_232.png: 512x640 1 car, 3 persons, 1 bicycle, 13.4ms\n",
            "image 25/433 /content/datasets/images/test/BJ_Baidu_384.png: 384x640 17 cars, 11.6ms\n",
            "image 26/433 /content/datasets/images/test/BJ_Baidu_447.png: 352x640 30 cars, 3 buss, 41.1ms\n",
            "image 27/433 /content/datasets/images/test/BJ_Baidu_536.png: 608x640 14 cars, 3 buss, 40.8ms\n",
            "image 28/433 /content/datasets/images/test/BJ_Baidu_842.png: 640x480 15 persons, 12.4ms\n",
            "image 29/433 /content/datasets/images/test/BJ_Baidu_966.png: 384x640 1 car, 1 person, 11.1ms\n",
            "image 30/433 /content/datasets/images/test/BJ_Bing_066.png: 576x640 6 cars, 45.2ms\n",
            "image 31/433 /content/datasets/images/test/BJ_Bing_076.png: 352x640 9 cars, 3 persons, 1 bicycle, 11.0ms\n",
            "image 32/433 /content/datasets/images/test/BJ_Bing_085.png: 608x640 1 bus, 22 persons, 16.3ms\n",
            "image 33/433 /content/datasets/images/test/BJ_Bing_206.png: 544x640 9 persons, 16.0ms\n",
            "image 34/433 /content/datasets/images/test/BJ_Bing_261.png: 448x640 9 persons, 13.4ms\n",
            "image 35/433 /content/datasets/images/test/BJ_Bing_392.png: 384x640 4 cars, 3 persons, 1 motorbike, 11.1ms\n",
            "image 36/433 /content/datasets/images/test/BJ_Bing_418.png: 512x640 7 persons, 13.5ms\n",
            "image 37/433 /content/datasets/images/test/BJ_Bing_446.png: 448x640 7 cars, 4 persons, 1 bicycle, 13.2ms\n",
            "image 38/433 /content/datasets/images/test/BJ_Bing_499.png: 640x640 10 cars, 16.5ms\n",
            "image 39/433 /content/datasets/images/test/BJ_Bing_630.png: 384x640 14 cars, 4 buss, 11.9ms\n",
            "image 40/433 /content/datasets/images/test/BJ_Bing_701.png: 512x640 85 cars, 4 buss, 13.5ms\n",
            "image 41/433 /content/datasets/images/test/BJ_Google_002.png: 384x640 4 persons, 1 motorbike, 11.1ms\n",
            "image 42/433 /content/datasets/images/test/BJ_Google_053.png: 448x640 1 bus, 13.7ms\n",
            "image 43/433 /content/datasets/images/test/BJ_Google_093.png: 448x640 2 persons, 12.7ms\n",
            "image 44/433 /content/datasets/images/test/BJ_Google_282.png: 384x640 2 persons, 11.8ms\n",
            "image 45/433 /content/datasets/images/test/BJ_Google_296.png: 608x640 2 cars, 16.6ms\n",
            "image 46/433 /content/datasets/images/test/BJ_Google_331.png: 576x640 2 cars, 17.2ms\n",
            "image 47/433 /content/datasets/images/test/BJ_Google_400.png: 384x640 1 person, 11.5ms\n",
            "image 48/433 /content/datasets/images/test/BJ_Google_44.png: 384x640 3 persons, 10.3ms\n",
            "image 49/433 /content/datasets/images/test/BJ_Google_608.png: 448x640 9 persons, 13.0ms\n",
            "image 50/433 /content/datasets/images/test/BJ_Google_631.png: 416x640 26 persons, 13.0ms\n",
            "image 51/433 /content/datasets/images/test/BL_Bing_020.png: 448x640 25 persons, 13.5ms\n",
            "image 52/433 /content/datasets/images/test/BL_Google_121.png: 544x640 13 cars, 5 buss, 2 persons, 1 motorbike, 15.7ms\n",
            "image 53/433 /content/datasets/images/test/BL_Google_173.png: 640x544 11 persons, 64.8ms\n",
            "image 54/433 /content/datasets/images/test/CC_Baidu_01.png: 448x640 23 cars, 2 buss, 1 person, 16.0ms\n",
            "image 55/433 /content/datasets/images/test/CC_Baidu_047.png: 576x640 28 cars, 4 buss, 15.7ms\n",
            "image 56/433 /content/datasets/images/test/CC_Baidu_147.png: 640x544 3 persons, 15.8ms\n",
            "image 57/433 /content/datasets/images/test/CC_Baidu_176.png: 352x640 13 cars, 2 persons, 10.8ms\n",
            "image 58/433 /content/datasets/images/test/CC_Baidu_244.png: 384x640 4 cars, 6 persons, 1 motorbike, 13.6ms\n",
            "image 59/433 /content/datasets/images/test/CC_Bing_070.png: 640x640 1 person, 16.4ms\n",
            "image 60/433 /content/datasets/images/test/CC_Bing_11.png: 576x640 3 cars, 1 bus, 9 persons, 1 bicycle, 15.7ms\n",
            "image 61/433 /content/datasets/images/test/CC_Bing_390.png: 512x640 1 person, 13.1ms\n",
            "image 62/433 /content/datasets/images/test/CC_Bing_436.png: 640x640 9 cars, 12 persons, 16.1ms\n",
            "image 63/433 /content/datasets/images/test/CC_Bing_548.png: 416x640 2 persons, 1 bicycle, 1 motorbike, 12.8ms\n",
            "image 64/433 /content/datasets/images/test/CC_Bing_637.png: 448x640 2 cars, 3 buss, 13.0ms\n",
            "image 65/433 /content/datasets/images/test/CC_Bing_683.png: 544x640 2 cars, 2 persons, 15.6ms\n",
            "image 66/433 /content/datasets/images/test/CC_Bing_689.png: 448x640 6 cars, 1 bus, 1 person, 13.0ms\n",
            "image 67/433 /content/datasets/images/test/CC_Bing_836.png: 448x640 9 persons, 1 motorbike, 12.2ms\n",
            "image 68/433 /content/datasets/images/test/CD_Baidu_012.png: 640x576 13 cars, 1 bus, 69.6ms\n",
            "image 69/433 /content/datasets/images/test/CD_Baidu_127.png: 544x640 48 cars, 4 buss, 15.7ms\n",
            "image 70/433 /content/datasets/images/test/CD_Baidu_434.png: 640x544 7 cars, 3 buss, 16.0ms\n",
            "image 71/433 /content/datasets/images/test/CD_Bing_214.png: 448x640 1 person, 1 motorbike, 14.0ms\n",
            "image 72/433 /content/datasets/images/test/CD_Bing_30.png: 416x640 13 cars, 1 bus, 2 persons, 1 motorbike, 13.1ms\n",
            "image 73/433 /content/datasets/images/test/CD_Bing_581.png: 640x544 2 buss, 1 person, 15.8ms\n",
            "image 74/433 /content/datasets/images/test/CD_Google_158.png: 480x640 2 cars, 1 bus, 1 person, 1 motorbike, 13.6ms\n",
            "image 75/433 /content/datasets/images/test/CD_Google_162.png: 384x640 1 car, 13.1ms\n",
            "image 76/433 /content/datasets/images/test/CD_Google_630.png: 480x640 6 persons, 13.3ms\n",
            "image 77/433 /content/datasets/images/test/CQ_Baidu_316.png: 320x640 1 car, 6 persons, 62.1ms\n",
            "image 78/433 /content/datasets/images/test/CQ_Bing_221.png: 448x640 44 cars, 1 bus, 13.0ms\n",
            "image 79/433 /content/datasets/images/test/CQ_Google_290.png: 544x640 1 car, 1 person, 15.8ms\n",
            "image 80/433 /content/datasets/images/test/CQ_Google_55.png: 352x640 5 cars, 1 bus, 10.8ms\n",
            "image 81/433 /content/datasets/images/test/FogDr_Bing_002.png: 512x640 2 cars, 13.2ms\n",
            "image 82/433 /content/datasets/images/test/FogDr_Bing_405.png: 384x640 2 cars, 10.9ms\n",
            "image 83/433 /content/datasets/images/test/FogDr_Bing_569.png: 416x640 1 car, 12.8ms\n",
            "image 84/433 /content/datasets/images/test/FogDr_Bing_648.png: 416x640 1 car, 12.1ms\n",
            "image 85/433 /content/datasets/images/test/FogDr_Google_003.png: 416x640 1 car, 11.9ms\n",
            "image 86/433 /content/datasets/images/test/FogDr_Google_031.png: 480x640 1 car, 1 bus, 14.2ms\n",
            "image 87/433 /content/datasets/images/test/FogDr_Google_040.png: 448x640 1 car, 13.9ms\n",
            "image 88/433 /content/datasets/images/test/FogDr_Google_045.png: 384x640 2 cars, 11.6ms\n",
            "image 89/433 /content/datasets/images/test/FogDr_Google_073.png: 480x640 2 cars, 14.0ms\n",
            "image 90/433 /content/datasets/images/test/FogDr_Google_076.png: 448x640 1 car, 1 person, 13.8ms\n",
            "image 91/433 /content/datasets/images/test/FogDr_Google_157.png: 416x640 2 cars, 13.6ms\n",
            "image 92/433 /content/datasets/images/test/FogDr_Google_215.png: 384x640 12 cars, 1 bus, 11.5ms\n",
            "image 93/433 /content/datasets/images/test/FogDr_Google_259.png: 480x640 1 car, 2 persons, 13.9ms\n",
            "image 94/433 /content/datasets/images/test/FogDr_Google_367.png: 480x640 1 person, 13.1ms\n",
            "image 95/433 /content/datasets/images/test/FogDr_Google_426.png: 384x640 3 cars, 4 buss, 11.8ms\n",
            "image 96/433 /content/datasets/images/test/FogDr_Google_713.png: 448x640 2 cars, 1 bus, 1 person, 13.9ms\n",
            "image 97/433 /content/datasets/images/test/FogDr_Google_756.png: 384x640 16 cars, 3 buss, 11.8ms\n",
            "image 98/433 /content/datasets/images/test/GRCN_Google_346.png: 448x640 1 person, 14.6ms\n",
            "image 99/433 /content/datasets/images/test/GRCN_Google_601.png: 480x640 1 person, 15.4ms\n",
            "image 100/433 /content/datasets/images/test/GSGL_Baidu_075.png: 416x640 28 cars, 5 buss, 13.9ms\n",
            "image 101/433 /content/datasets/images/test/GSGL_Baidu_1034.png: 448x640 2 cars, 14.3ms\n",
            "image 102/433 /content/datasets/images/test/GSGL_Baidu_1035.png: 448x640 132 cars, 13 buss, 13.0ms\n",
            "image 103/433 /content/datasets/images/test/GSGL_Baidu_113.png: 512x640 49 cars, 1 person, 1 motorbike, 14.5ms\n",
            "image 104/433 /content/datasets/images/test/GSGL_Baidu_1139.png: 416x640 4 cars, 5 persons, 14.2ms\n",
            "image 105/433 /content/datasets/images/test/GSGL_Baidu_1191.png: 320x640 1 car, 1 bus, 3 persons, 12.1ms\n",
            "image 106/433 /content/datasets/images/test/GSGL_Baidu_133.png: 320x640 3 cars, 11 persons, 11.2ms\n",
            "image 107/433 /content/datasets/images/test/GSGL_Baidu_145.png: 384x640 10 persons, 1 motorbike, 11.9ms\n",
            "image 108/433 /content/datasets/images/test/GSGL_Baidu_198.png: 640x480 15 cars, 1 bus, 1 person, 13.1ms\n",
            "image 109/433 /content/datasets/images/test/GSGL_Baidu_200.png: 640x320 1 person, 1 motorbike, 41.0ms\n",
            "image 110/433 /content/datasets/images/test/GSGL_Baidu_229.png: 480x640 4 cars, 1 bus, 13.8ms\n",
            "image 111/433 /content/datasets/images/test/GSGL_Baidu_300.png: 448x640 1 car, 6 persons, 14.0ms\n",
            "image 112/433 /content/datasets/images/test/GSGL_Baidu_424.png: 416x640 13 cars, 5 buss, 13.5ms\n",
            "image 113/433 /content/datasets/images/test/GSGL_Baidu_427.png: 448x640 3 cars, 2 buss, 4 persons, 13.7ms\n",
            "image 114/433 /content/datasets/images/test/GSGL_Baidu_479.png: 416x640 20 cars, 4 buss, 13.4ms\n",
            "image 115/433 /content/datasets/images/test/GSGL_Baidu_501.png: 448x640 8 cars, 1 bus, 13.6ms\n",
            "image 116/433 /content/datasets/images/test/GSGL_Baidu_587.png: 544x640 9 cars, 5 persons, 1 motorbike, 16.3ms\n",
            "image 117/433 /content/datasets/images/test/GSGL_Baidu_616.png: 640x608 38 cars, 4 buss, 43.0ms\n",
            "image 118/433 /content/datasets/images/test/GSGL_Baidu_656.png: 448x640 5 cars, 1 bus, 12.6ms\n",
            "image 119/433 /content/datasets/images/test/GSGL_Baidu_662.png: 352x640 65 cars, 2 buss, 3 persons, 10.8ms\n",
            "image 120/433 /content/datasets/images/test/GSGL_Baidu_677.png: 384x640 72 cars, 1 bus, 1 bicycle, 10.4ms\n",
            "image 121/433 /content/datasets/images/test/GSGL_Baidu_726.png: 640x640 28 cars, 5 buss, 4 persons, 15.6ms\n",
            "image 122/433 /content/datasets/images/test/GSGL_Baidu_866.png: 384x640 9 cars, 1 bus, 3 persons, 10.4ms\n",
            "image 123/433 /content/datasets/images/test/GSGL_Baidu_879.png: 448x640 87 cars, 4 buss, 12.8ms\n",
            "image 124/433 /content/datasets/images/test/GSGL_Baidu_906.png: 384x640 4 persons, 1 bicycle, 1 motorbike, 12.2ms\n",
            "image 125/433 /content/datasets/images/test/GSGL_Bing_095.png: 544x640 3 persons, 15.1ms\n",
            "image 126/433 /content/datasets/images/test/GSGL_Bing_198.png: 352x640 5 cars, 2 buss, 10.3ms\n",
            "image 127/433 /content/datasets/images/test/GSGL_Bing_372.png: 384x640 3 cars, 10.5ms\n",
            "image 128/433 /content/datasets/images/test/GSGL_Bing_44.png: 288x640 7 cars, 1 bus, 2 persons, 10.1ms\n",
            "image 129/433 /content/datasets/images/test/GSGL_Bing_567.png: 544x640 3 persons, 15.1ms\n",
            "image 130/433 /content/datasets/images/test/GSGL_Bing_597.png: 352x640 3 cars, 9 persons, 1 bicycle, 5 motorbikes, 10.4ms\n",
            "image 131/433 /content/datasets/images/test/GSGL_Google_004.png: 384x640 1 car, 10.7ms\n",
            "image 132/433 /content/datasets/images/test/GSGL_Google_009.png: 384x640 4 cars, 1 bus, 1 person, 9.8ms\n",
            "image 133/433 /content/datasets/images/test/GSGL_Google_013.png: 416x640 2 cars, 1 bus, 1 person, 11.3ms\n",
            "image 134/433 /content/datasets/images/test/GSGL_Google_227.png: 384x640 2 cars, 1 bus, 9.6ms\n",
            "image 135/433 /content/datasets/images/test/GSGL_Google_402.png: 384x640 1 car, 1 bus, 8.9ms\n",
            "image 136/433 /content/datasets/images/test/GSGL_Google_663.png: 480x640 7 cars, 3 buss, 2 persons, 11.7ms\n",
            "image 137/433 /content/datasets/images/test/HC_Google_524.png: 384x640 39 cars, 10.1ms\n",
            "image 138/433 /content/datasets/images/test/HEB_Baidu_09.png: 480x640 2 cars, 3 persons, 11.7ms\n",
            "image 139/433 /content/datasets/images/test/HEB_Baidu_472.png: 640x640 8 cars, 1 bus, 14.3ms\n",
            "image 140/433 /content/datasets/images/test/HEB_Baidu_497.png: 480x640 9 cars, 11.6ms\n",
            "image 141/433 /content/datasets/images/test/HEB_Baidu_554.png: 448x640 1 car, 1 person, 11.2ms\n",
            "image 142/433 /content/datasets/images/test/HEB_Baidu_698.png: 448x640 1 person, 10.5ms\n",
            "image 143/433 /content/datasets/images/test/HEB_Baidu_706.png: 480x640 1 car, 11.2ms\n",
            "image 144/433 /content/datasets/images/test/HEB_Baidu_806.png: 416x640 13 persons, 11.0ms\n",
            "image 145/433 /content/datasets/images/test/HEB_Baidu_831.png: 384x640 1 person, 9.3ms\n",
            "image 146/433 /content/datasets/images/test/HEB_Baidu_848.png: 416x640 2 cars, 8 persons, 10.9ms\n",
            "image 147/433 /content/datasets/images/test/HEB_Bing_136.png: 576x640 1 car, 1 person, 1 bicycle, 13.5ms\n",
            "image 148/433 /content/datasets/images/test/HEB_Bing_254.png: 384x640 5 persons, 9.3ms\n",
            "image 149/433 /content/datasets/images/test/HEB_Bing_269.png: 448x640 4 cars, 3 buss, 1 person, 11.1ms\n",
            "image 150/433 /content/datasets/images/test/HEB_Bing_444.png: 544x640 33 cars, 2 buss, 2 persons, 1 motorbike, 13.3ms\n",
            "image 151/433 /content/datasets/images/test/HEB_Bing_452.png: 576x640 6 cars, 1 bus, 1 person, 1 motorbike, 13.4ms\n",
            "image 152/433 /content/datasets/images/test/HEB_Bing_511.png: 352x640 5 cars, 1 person, 9.2ms\n",
            "image 153/433 /content/datasets/images/test/HEB_Bing_587.png: 416x640 18 cars, 7 buss, 2 persons, 10.9ms\n",
            "image 154/433 /content/datasets/images/test/HEB_Google_258.png: 416x640 7 persons, 10.2ms\n",
            "image 155/433 /content/datasets/images/test/HEB_Google_550.png: 352x640 24 cars, 9.2ms\n",
            "image 156/433 /content/datasets/images/test/HEB_Google_618.png: 640x512 2 persons, 41.7ms\n",
            "image 157/433 /content/datasets/images/test/HEB_Google_651.png: 448x640 8 cars, 11.3ms\n",
            "image 158/433 /content/datasets/images/test/HEB_Google_664.png: 480x640 3 cars, 12 persons, 11.8ms\n",
            "image 159/433 /content/datasets/images/test/HF_Baidu_017.png: 480x640 2 cars, 1 bus, 1 person, 10.7ms\n",
            "image 160/433 /content/datasets/images/test/HF_Baidu_146.png: 640x608 7 persons, 13.7ms\n",
            "image 161/433 /content/datasets/images/test/HF_Bing_100.png: 480x640 16 cars, 1 bus, 11.3ms\n",
            "image 162/433 /content/datasets/images/test/HF_Bing_366.png: 448x640 2 persons, 1 motorbike, 11.1ms\n",
            "image 163/433 /content/datasets/images/test/HF_Bing_627.png: 544x640 139 cars, 3 buss, 13.7ms\n",
            "image 164/433 /content/datasets/images/test/HF_Bing_679.png: 544x640 7 cars, 3 persons, 1 motorbike, 12.6ms\n",
            "image 165/433 /content/datasets/images/test/HF_Bing_685.png: 416x640 2 persons, 10.9ms\n",
            "image 166/433 /content/datasets/images/test/HF_Google_045.png: 448x640 20 cars, 4 buss, 11.1ms\n",
            "image 167/433 /content/datasets/images/test/HF_Google_091.png: 384x640 20 cars, 1 bus, 10.3ms\n",
            "image 168/433 /content/datasets/images/test/HF_Google_133.png: 480x640 14 cars, 11.3ms\n",
            "image 169/433 /content/datasets/images/test/HF_Google_153.png: 384x640 12 persons, 1 motorbike, 9.5ms\n",
            "image 170/433 /content/datasets/images/test/HF_Google_443.png: 416x640 18 cars, 1 bus, 10.9ms\n",
            "image 171/433 /content/datasets/images/test/HF_Google_472.png: 448x640 5 cars, 2 buss, 11.3ms\n",
            "image 172/433 /content/datasets/images/test/HF_Google_861.png: 640x544 3 persons, 13.9ms\n",
            "image 173/433 /content/datasets/images/test/HazeDr_Bing_330.png: 448x640 2 persons, 2 motorbikes, 11.2ms\n",
            "image 174/433 /content/datasets/images/test/HazeDr_Google_183.png: 448x640 3 cars, 10.5ms\n",
            "image 175/433 /content/datasets/images/test/HazeDr_Google_273.png: 384x640 2 cars, 2 buss, 2 persons, 2 motorbikes, 9.3ms\n",
            "image 176/433 /content/datasets/images/test/HazeDr_Google_404.png: 640x480 9 persons, 10.5ms\n",
            "image 177/433 /content/datasets/images/test/HazeDr_Google_594.png: 384x640 1 car, 9.4ms\n",
            "image 178/433 /content/datasets/images/test/HazeDr_Google_651.png: 512x640 5 cars, 11.4ms\n",
            "image 179/433 /content/datasets/images/test/HazeDr_Google_845.png: 384x640 5 persons, 9.3ms\n",
            "image 180/433 /content/datasets/images/test/HazyDr_Bing_194.png: 448x640 (no detections), 11.2ms\n",
            "image 181/433 /content/datasets/images/test/HazyDr_Bing_557.png: 448x640 8 persons, 10.5ms\n",
            "image 182/433 /content/datasets/images/test/HazyDr_Google_138.png: 448x640 2 cars, 11.4ms\n",
            "image 183/433 /content/datasets/images/test/HazyDr_Google_678.png: 480x640 12 cars, 1 bus, 15.7ms\n",
            "image 184/433 /content/datasets/images/test/IRQ_Bing_228.png: 416x640 9 persons, 11.0ms\n",
            "image 185/433 /content/datasets/images/test/IRQ_Bing_674.png: 448x640 6 cars, 8 persons, 1 bicycle, 4 motorbikes, 11.2ms\n",
            "image 186/433 /content/datasets/images/test/IRQ_Google_077.png: 352x640 5 persons, 9.2ms\n",
            "image 187/433 /content/datasets/images/test/IRQ_Google_084.png: 448x640 2 cars, 1 bus, 11.2ms\n",
            "image 188/433 /content/datasets/images/test/IRQ_Google_115.png: 416x640 1 bus, 2 persons, 13.5ms\n",
            "image 189/433 /content/datasets/images/test/IRQ_Google_210.png: 352x640 2 persons, 11.3ms\n",
            "image 190/433 /content/datasets/images/test/IRQ_Google_495.png: 384x640 2 cars, 1 bus, 2 persons, 11.3ms\n",
            "image 191/433 /content/datasets/images/test/JL_Baidu_146.png: 448x640 1 car, 1 person, 1 bicycle, 13.6ms\n",
            "image 192/433 /content/datasets/images/test/JL_Bing_05.png: 512x640 5 persons, 13.8ms\n",
            "image 193/433 /content/datasets/images/test/JL_Bing_767.png: 640x640 4 cars, 3 buss, 2 persons, 16.8ms\n",
            "image 194/433 /content/datasets/images/test/JL_Google_104.png: 384x640 2 cars, 3 persons, 12.5ms\n",
            "image 195/433 /content/datasets/images/test/JL_Google_288.png: 384x640 (no detections), 10.2ms\n",
            "image 196/433 /content/datasets/images/test/JL_Google_397.png: 608x640 8 cars, 2 buss, 1 person, 16.0ms\n",
            "image 197/433 /content/datasets/images/test/JL_Google_674.png: 448x640 3 persons, 13.1ms\n",
            "image 198/433 /content/datasets/images/test/KRO_Google_142.png: 320x640 3 cars, 2 persons, 10.6ms\n",
            "image 199/433 /content/datasets/images/test/KRO_Google_20.png: 448x640 13 cars, 1 person, 13.0ms\n",
            "image 200/433 /content/datasets/images/test/KRO_Google_317.png: 480x640 6 persons, 13.3ms\n",
            "image 201/433 /content/datasets/images/test/KRO_Google_419.png: 448x640 2 persons, 2 bicycles, 13.0ms\n",
            "image 202/433 /content/datasets/images/test/LSJ_Baidu_065.png: 416x640 1 person, 12.6ms\n",
            "image 203/433 /content/datasets/images/test/LSJ_Baidu_110.png: 448x640 1 person, 13.3ms\n",
            "image 204/433 /content/datasets/images/test/LSJ_Baidu_1193.png: 480x640 3 persons, 13.0ms\n",
            "image 205/433 /content/datasets/images/test/LSJ_Baidu_975.png: 448x640 1 person, 12.8ms\n",
            "image 206/433 /content/datasets/images/test/LSJ_Google_260.png: 448x640 1 person, 12.1ms\n",
            "image 207/433 /content/datasets/images/test/LZ_Baidu_059.png: 544x640 22 cars, 3 buss, 9 persons, 15.5ms\n",
            "image 208/433 /content/datasets/images/test/LZ_Bing_044.png: 384x640 1 car, 1 person, 10.6ms\n",
            "image 209/433 /content/datasets/images/test/LZ_Bing_088.png: 640x640 4 persons, 16.0ms\n",
            "image 210/433 /content/datasets/images/test/LZ_Bing_279.png: 416x640 3 persons, 1 bicycle, 1 motorbike, 12.5ms\n",
            "image 211/433 /content/datasets/images/test/LZ_Bing_573.png: 512x640 1 person, 1 bicycle, 12.8ms\n",
            "image 212/433 /content/datasets/images/test/LZ_Google_014.png: 448x640 1 person, 12.8ms\n",
            "image 213/433 /content/datasets/images/test/LZ_Google_355.png: 448x640 1 person, 12.1ms\n",
            "image 214/433 /content/datasets/images/test/MLS_Bing_174.png: 384x640 2 persons, 10.6ms\n",
            "image 215/433 /content/datasets/images/test/MLS_Bing_637.png: 448x640 1 person, 11.0ms\n",
            "image 216/433 /content/datasets/images/test/MLS_Bing_686.png: 448x640 1 person, 10.3ms\n",
            "image 217/433 /content/datasets/images/test/MLS_Bing_737.png: 448x640 2 cars, 6 persons, 10.3ms\n",
            "image 218/433 /content/datasets/images/test/MLS_Google_06.png: 416x640 1 person, 1 motorbike, 10.8ms\n",
            "image 219/433 /content/datasets/images/test/MLS_Google_081.png: 448x640 1 person, 1 motorbike, 11.2ms\n",
            "image 220/433 /content/datasets/images/test/MLS_Google_314.png: 448x640 1 person, 10.3ms\n",
            "image 221/433 /content/datasets/images/test/MLS_Google_322.png: 448x640 (no detections), 10.3ms\n",
            "image 222/433 /content/datasets/images/test/MLS_Google_653.png: 448x640 12 cars, 3 buss, 3 persons, 1 motorbike, 10.3ms\n",
            "image 223/433 /content/datasets/images/test/MSK_Bing_044.png: 640x544 28 cars, 1 bus, 13.3ms\n",
            "image 224/433 /content/datasets/images/test/MSK_Bing_120.png: 448x640 7 cars, 1 bus, 1 person, 11.2ms\n",
            "image 225/433 /content/datasets/images/test/MSK_Bing_160.png: 480x640 2 persons, 11.2ms\n",
            "image 226/433 /content/datasets/images/test/MSK_Bing_293.png: 544x640 15 cars, 2 buss, 1 person, 13.7ms\n",
            "image 227/433 /content/datasets/images/test/MSK_Bing_445.png: 640x480 6 cars, 2 persons, 10.4ms\n",
            "image 228/433 /content/datasets/images/test/MSK_Bing_612.png: 480x640 19 cars, 1 bus, 1 person, 11.3ms\n",
            "image 229/433 /content/datasets/images/test/NW_Google_117.png: 448x640 1 person, 11.0ms\n",
            "image 230/433 /content/datasets/images/test/NY_Baidu_073.png: 384x640 2 cars, 4 buss, 8 persons, 9.3ms\n",
            "image 231/433 /content/datasets/images/test/NY_Baidu_138.png: 416x640 1 car, 5 persons, 10.9ms\n",
            "image 232/433 /content/datasets/images/test/NY_Baidu_562.png: 448x640 13 cars, 2 buss, 1 person, 11.0ms\n",
            "image 233/433 /content/datasets/images/test/NY_Bing_29.png: 416x640 1 car, 1 bus, 2 persons, 10.7ms\n",
            "image 234/433 /content/datasets/images/test/NZL_Bing_157.png: 480x640 1 person, 11.1ms\n",
            "image 235/433 /content/datasets/images/test/NZL_Bing_359.png: 416x640 2 persons, 10.8ms\n",
            "image 236/433 /content/datasets/images/test/NZL_Google_240.png: 640x448 1 person, 38.4ms\n",
            "image 237/433 /content/datasets/images/test/NZL_Google_294.png: 384x640 1 bus, 5 persons, 9.2ms\n",
            "image 238/433 /content/datasets/images/test/NZL_Google_446.png: 320x640 1 person, 9.0ms\n",
            "image 239/433 /content/datasets/images/test/NZL_Google_463.png: 448x640 5 persons, 11.1ms\n",
            "image 240/433 /content/datasets/images/test/OLD_Google_021.png: 384x640 3 cars, 9.1ms\n",
            "image 241/433 /content/datasets/images/test/OLD_Google_049.png: 288x640 1 car, 8.8ms\n",
            "image 242/433 /content/datasets/images/test/PL_Google_394.png: 448x640 1 person, 11.1ms\n",
            "image 243/433 /content/datasets/images/test/PL_Google_756.png: 480x640 1 person, 1 motorbike, 11.1ms\n",
            "image 244/433 /content/datasets/images/test/QC_Baidu_525.png: 448x640 2 buss, 1 person, 11.0ms\n",
            "image 245/433 /content/datasets/images/test/QC_Baidu_544.png: 416x640 1 car, 10.7ms\n",
            "image 246/433 /content/datasets/images/test/QC_Baidu_572.png: 352x640 1 car, 9.1ms\n",
            "image 247/433 /content/datasets/images/test/QC_Bing_209.png: 480x640 1 person, 11.1ms\n",
            "image 248/433 /content/datasets/images/test/QC_Bing_236.png: 416x640 1 car, 10.8ms\n",
            "image 249/433 /content/datasets/images/test/QC_Bing_266.png: 352x640 3 persons, 9.1ms\n",
            "image 250/433 /content/datasets/images/test/QC_Bing_555.png: 512x640 3 cars, 11.2ms\n",
            "image 251/433 /content/datasets/images/test/QC_Bing_618.png: 448x640 1 car, 10.8ms\n",
            "image 252/433 /content/datasets/images/test/QD_Bing_124.png: 576x640 10 cars, 6 persons, 13.1ms\n",
            "image 253/433 /content/datasets/images/test/QD_Bing_143.png: 448x640 1 person, 10.8ms\n",
            "image 254/433 /content/datasets/images/test/QD_Bing_439.png: 544x640 5 persons, 12.8ms\n",
            "image 255/433 /content/datasets/images/test/QD_Google_019.png: 384x640 1 person, 9.1ms\n",
            "image 256/433 /content/datasets/images/test/SFC_Bing_448.png: 480x640 1 person, 11.0ms\n",
            "image 257/433 /content/datasets/images/test/SFC_Google_209.png: 480x640 1 person, 10.3ms\n",
            "image 258/433 /content/datasets/images/test/SGP_Bing_080.png: 288x640 1 car, 5 persons, 8.7ms\n",
            "image 259/433 /content/datasets/images/test/SGP_Bing_090.png: 416x640 8 persons, 10.6ms\n",
            "image 260/433 /content/datasets/images/test/SGP_Bing_097.png: 448x640 3 persons, 10.9ms\n",
            "image 261/433 /content/datasets/images/test/SGP_Bing_231.png: 256x640 1 car, 4 persons, 39.1ms\n",
            "image 262/433 /content/datasets/images/test/SGP_Bing_264.png: 448x640 7 cars, 1 bus, 10.8ms\n",
            "image 263/433 /content/datasets/images/test/SGP_Bing_551.png: 352x640 1 person, 8.9ms\n",
            "image 264/433 /content/datasets/images/test/SGP_Google_080.png: 448x640 3 persons, 10.8ms\n",
            "image 265/433 /content/datasets/images/test/SGP_Google_161.png: 448x640 4 persons, 10.1ms\n",
            "image 266/433 /content/datasets/images/test/SGP_Google_223.png: 448x640 5 persons, 10.2ms\n",
            "image 267/433 /content/datasets/images/test/SH_Bing_156.png: 416x640 1 car, 2 persons, 11.1ms\n",
            "image 268/433 /content/datasets/images/test/SH_Bing_228.png: 448x640 1 person, 10.9ms\n",
            "image 269/433 /content/datasets/images/test/SH_Bing_274.png: 480x640 1 car, 4 persons, 1 bicycle, 1 motorbike, 11.0ms\n",
            "image 270/433 /content/datasets/images/test/SH_Bing_465.png: 384x640 7 cars, 2 buss, 6 persons, 9.1ms\n",
            "image 271/433 /content/datasets/images/test/SH_Google_353.png: 544x640 5 persons, 13.0ms\n",
            "image 272/433 /content/datasets/images/test/SH_Google_383.png: 576x640 1 car, 5 persons, 1 bicycle, 2 motorbikes, 13.0ms\n",
            "image 273/433 /content/datasets/images/test/SH_Google_516.png: 480x640 8 persons, 11.0ms\n",
            "image 274/433 /content/datasets/images/test/SJZ_Baidu_184.png: 576x640 32 cars, 1 bus, 13.0ms\n",
            "image 275/433 /content/datasets/images/test/SJZ_Baidu_209.png: 416x640 11 cars, 1 person, 10.5ms\n",
            "image 276/433 /content/datasets/images/test/SJZ_Baidu_381.png: 384x640 5 cars, 1 bus, 9.0ms\n",
            "image 277/433 /content/datasets/images/test/SJZ_Baidu_418.png: 416x640 28 cars, 1 bus, 10.6ms\n",
            "image 278/433 /content/datasets/images/test/SJZ_Baidu_892.png: 448x640 22 cars, 1 bus, 2 persons, 10.9ms\n",
            "image 279/433 /content/datasets/images/test/SJZ_Bing_146.png: 576x640 2 persons, 13.4ms\n",
            "image 280/433 /content/datasets/images/test/SJZ_Bing_492.png: 480x640 1 bus, 2 persons, 1 bicycle, 11.1ms\n",
            "image 281/433 /content/datasets/images/test/SJZ_Bing_593.png: 640x480 3 cars, 12.1ms\n",
            "image 282/433 /content/datasets/images/test/SJZ_Bing_794.png: 384x640 2 cars, 1 bus, 6 persons, 1 bicycle, 9.1ms\n",
            "image 283/433 /content/datasets/images/test/SJZ_Bing_812.png: 640x544 4 cars, 1 bus, 3 persons, 1 bicycle, 2 motorbikes, 13.0ms\n",
            "image 284/433 /content/datasets/images/test/SJZ_Google_339.png: 352x640 17 cars, 8.9ms\n",
            "image 285/433 /content/datasets/images/test/SJZ_Google_404.png: 448x640 3 persons, 1 bicycle, 1 motorbike, 10.9ms\n",
            "image 286/433 /content/datasets/images/test/SY_Baidu_056.png: 448x640 38 cars, 5 buss, 10.2ms\n",
            "image 287/433 /content/datasets/images/test/SY_Baidu_186.png: 448x640 2 persons, 10.2ms\n",
            "image 288/433 /content/datasets/images/test/SY_Bing_336.png: 448x640 3 persons, 10.2ms\n",
            "image 289/433 /content/datasets/images/test/SY_Google_189.png: 448x640 2 cars, 1 bus, 4 persons, 2 bicycles, 3 motorbikes, 10.2ms\n",
            "image 290/433 /content/datasets/images/test/SY_Google_260.png: 480x640 1 car, 2 persons, 11.0ms\n",
            "image 291/433 /content/datasets/images/test/SY_Google_321.png: 448x640 7 cars, 10.9ms\n",
            "image 292/433 /content/datasets/images/test/SY_Google_398.png: 352x640 16 cars, 1 bus, 8.9ms\n",
            "image 293/433 /content/datasets/images/test/TJ_Baidu_1012.png: 480x640 3 persons, 11.0ms\n",
            "image 294/433 /content/datasets/images/test/TJ_Baidu_368.png: 416x640 13 cars, 5 persons, 10.6ms\n",
            "image 295/433 /content/datasets/images/test/TJ_Baidu_398.png: 384x640 4 persons, 9.1ms\n",
            "image 296/433 /content/datasets/images/test/TJ_Baidu_534.png: 384x640 8 cars, 1 bus, 8.4ms\n",
            "image 297/433 /content/datasets/images/test/TJ_Baidu_843.png: 384x640 1 car, 8 persons, 1 motorbike, 8.4ms\n",
            "image 298/433 /content/datasets/images/test/TKO_Google_805.png: 512x640 10 cars, 2 buss, 1 person, 11.0ms\n",
            "image 299/433 /content/datasets/images/test/TKO_Google_824.png: 480x640 13 persons, 11.1ms\n",
            "image 300/433 /content/datasets/images/test/TS_Baidu_006.png: 448x640 1 car, 6 persons, 10.9ms\n",
            "image 301/433 /content/datasets/images/test/TS_Baidu_039.png: 608x640 (no detections), 13.3ms\n",
            "image 302/433 /content/datasets/images/test/TS_Baidu_374.png: 512x640 3 persons, 2 motorbikes, 11.0ms\n",
            "image 303/433 /content/datasets/images/test/TS_Google_400.png: 384x640 7 cars, 9.1ms\n",
            "image 304/433 /content/datasets/images/test/TS_Google_519.png: 480x640 1 car, 5 persons, 1 motorbike, 10.9ms\n",
            "image 305/433 /content/datasets/images/test/WST_Google_354.png: 320x640 2 cars, 5 persons, 9.0ms\n",
            "image 306/433 /content/datasets/images/test/WST_Google_710.png: 448x640 1 person, 10.8ms\n",
            "image 307/433 /content/datasets/images/test/XA_Baidu_014.png: 384x640 26 cars, 3 buss, 9.0ms\n",
            "image 308/433 /content/datasets/images/test/XA_Baidu_034.png: 448x640 12 cars, 10.9ms\n",
            "image 309/433 /content/datasets/images/test/XA_Baidu_038.png: 480x640 8 persons, 7 bicycles, 11.8ms\n",
            "image 310/433 /content/datasets/images/test/XA_Baidu_180.png: 352x640 1 car, 6 persons, 9.7ms\n",
            "image 311/433 /content/datasets/images/test/XA_Baidu_208.png: 640x576 11 cars, 3 buss, 14.1ms\n",
            "image 312/433 /content/datasets/images/test/XA_Bing_087.png: 544x640 14 cars, 1 bus, 14.4ms\n",
            "image 313/433 /content/datasets/images/test/XA_Bing_120.png: 544x640 2 persons, 2 motorbikes, 13.3ms\n",
            "image 314/433 /content/datasets/images/test/XA_Bing_170.png: 384x640 6 cars, 4 buss, 1 person, 9.8ms\n",
            "image 315/433 /content/datasets/images/test/XA_Bing_282.png: 384x640 9 persons, 9.1ms\n",
            "image 316/433 /content/datasets/images/test/XA_Bing_733.png: 384x640 1 car, 3 buss, 6 persons, 1 motorbike, 9.1ms\n",
            "image 317/433 /content/datasets/images/test/XA_Bing_767.png: 512x640 10 cars, 1 person, 11.8ms\n",
            "image 318/433 /content/datasets/images/test/XA_Google_040.png: 640x640 7 persons, 14.5ms\n",
            "image 319/433 /content/datasets/images/test/XA_Google_378.png: 544x640 13 cars, 1 bus, 14.0ms\n",
            "image 320/433 /content/datasets/images/test/XA_Google_586.png: 576x640 1 bus, 2 persons, 14.1ms\n",
            "image 321/433 /content/datasets/images/test/XG_Baidu_409.png: 640x480 1 person, 11.1ms\n",
            "image 322/433 /content/datasets/images/test/XG_Baidu_627.png: 480x640 2 persons, 12.1ms\n",
            "image 323/433 /content/datasets/images/test/XG_Baidu_634.png: 448x640 2 persons, 11.9ms\n",
            "image 324/433 /content/datasets/images/test/XG_Baidu_829.png: 384x640 4 persons, 9.9ms\n",
            "image 325/433 /content/datasets/images/test/XG_Bing_176.png: 448x640 4 persons, 1 motorbike, 11.8ms\n",
            "image 326/433 /content/datasets/images/test/XG_Bing_198.png: 416x640 12 cars, 1 bus, 12.0ms\n",
            "image 327/433 /content/datasets/images/test/XG_Google_528.png: 416x640 11 cars, 2 persons, 11.0ms\n",
            "image 328/433 /content/datasets/images/test/XG_Google_646.png: 384x640 3 persons, 10.6ms\n",
            "image 329/433 /content/datasets/images/test/XR_Baidu_006.png: 384x640 6 cars, 3 persons, 9.3ms\n",
            "image 330/433 /content/datasets/images/test/XR_Baidu_014.png: 512x640 3 cars, 3 buss, 1 person, 12.0ms\n",
            "image 331/433 /content/datasets/images/test/XR_Baidu_096.png: 448x640 12 cars, 1 bus, 15 persons, 8 bicycles, 11.9ms\n",
            "image 332/433 /content/datasets/images/test/XR_Baidu_120.png: 480x640 1 car, 3 buss, 12.1ms\n",
            "image 333/433 /content/datasets/images/test/XR_Baidu_131.png: 416x640 8 cars, 1 bus, 2 persons, 11.7ms\n",
            "image 334/433 /content/datasets/images/test/XR_Baidu_221.png: 544x640 3 cars, 1 bus, 3 persons, 14.3ms\n",
            "image 335/433 /content/datasets/images/test/XR_Baidu_262.png: 640x640 67 cars, 10 buss, 15.4ms\n",
            "image 336/433 /content/datasets/images/test/XR_Baidu_276.png: 352x640 2 cars, 10.8ms\n",
            "image 337/433 /content/datasets/images/test/XR_Baidu_301.png: 448x640 8 cars, 2 buss, 12.6ms\n",
            "image 338/433 /content/datasets/images/test/XR_Baidu_45.png: 448x640 2 persons, 1 motorbike, 11.4ms\n",
            "image 339/433 /content/datasets/images/test/XR_Baidu_466.png: 416x640 10 cars, 2 buss, 12.8ms\n",
            "image 340/433 /content/datasets/images/test/XR_Baidu_471.png: 448x640 2 cars, 1 person, 12.8ms\n",
            "image 341/433 /content/datasets/images/test/XR_Bing_211.png: 544x640 9 persons, 22.2ms\n",
            "image 342/433 /content/datasets/images/test/XR_Bing_463.png: 384x640 2 cars, 1 person, 12.7ms\n",
            "image 343/433 /content/datasets/images/test/XR_Bing_499.png: 352x640 4 cars, 24.4ms\n",
            "image 344/433 /content/datasets/images/test/XR_Google_067.png: 320x640 2 cars, 2 persons, 2 motorbikes, 12.3ms\n",
            "image 345/433 /content/datasets/images/test/XR_Google_105.png: 512x640 5 cars, 1 bus, 3 persons, 1 bicycle, 13.2ms\n",
            "image 346/433 /content/datasets/images/test/XR_Google_34.png: 640x640 3 persons, 16.3ms\n",
            "image 347/433 /content/datasets/images/test/XR_Google_403.png: 544x640 5 persons, 15.8ms\n",
            "image 348/433 /content/datasets/images/test/XR_Google_538.png: 416x640 1 person, 13.1ms\n",
            "image 349/433 /content/datasets/images/test/XR_Google_626.png: 480x640 1 car, 1 person, 1 motorbike, 21.8ms\n",
            "image 350/433 /content/datasets/images/test/XR_Google_689.png: 576x640 5 persons, 1 bicycle, 4 motorbikes, 15.9ms\n",
            "image 351/433 /content/datasets/images/test/XR_Google_721.png: 576x640 3 persons, 26.1ms\n",
            "image 352/433 /content/datasets/images/test/YC_Bing_311.png: 512x640 6 persons, 13.7ms\n",
            "image 353/433 /content/datasets/images/test/YD_Baidu_068.png: 384x640 2 persons, 15.2ms\n",
            "image 354/433 /content/datasets/images/test/YD_Bing_429.png: 384x640 1 person, 25.6ms\n",
            "image 355/433 /content/datasets/images/test/YD_Google_017.png: 448x640 3 persons, 18.6ms\n",
            "image 356/433 /content/datasets/images/test/YD_Google_255.png: 544x640 4 persons, 34.0ms\n",
            "image 357/433 /content/datasets/images/test/YSM_Google_602.png: 448x640 6 cars, 1 bus, 23.9ms\n",
            "image 358/433 /content/datasets/images/test/YT_Bing_065.png: 416x640 3 cars, 1 person, 13.5ms\n",
            "image 359/433 /content/datasets/images/test/hv11_286.png: 352x640 5 cars, 11.0ms\n",
            "image 360/433 /content/datasets/images/test/hv12_1482.png: 384x640 8 cars, 11.3ms\n",
            "image 361/433 /content/datasets/images/test/hv12_171.png: 384x640 3 cars, 1 person, 10.6ms\n",
            "image 362/433 /content/datasets/images/test/hv12_2202.png: 384x640 10 cars, 1 person, 10.7ms\n",
            "image 363/433 /content/datasets/images/test/hv12_286.png: 384x640 3 cars, 10.7ms\n",
            "image 364/433 /content/datasets/images/test/hv14_139.png: 384x640 3 cars, 10.6ms\n",
            "image 365/433 /content/datasets/images/test/hv15_23.png: 384x640 2 cars, 1 bus, 11.1ms\n",
            "image 366/433 /content/datasets/images/test/hv15_41.png: 384x640 6 cars, 1 bus, 10.7ms\n",
            "image 367/433 /content/datasets/images/test/hv15_6.png: 384x640 5 cars, 10.7ms\n",
            "image 368/433 /content/datasets/images/test/hv15_73.png: 384x640 6 cars, 10.6ms\n",
            "image 369/433 /content/datasets/images/test/hv16_108.png: 384x640 2 persons, 10.7ms\n",
            "image 370/433 /content/datasets/images/test/hv17_1.png: 384x640 4 cars, 10.7ms\n",
            "image 371/433 /content/datasets/images/test/hv17_31.png: 384x640 10 cars, 1 person, 10.6ms\n",
            "image 372/433 /content/datasets/images/test/hv1_78.png: 448x640 10 cars, 13.7ms\n",
            "image 373/433 /content/datasets/images/test/hv1_93.png: 448x640 4 cars, 1 person, 13.0ms\n",
            "image 374/433 /content/datasets/images/test/hv20_231.png: 384x640 2 cars, 11.7ms\n",
            "image 375/433 /content/datasets/images/test/hv21_266.png: 352x640 1 car, 11.3ms\n",
            "image 376/433 /content/datasets/images/test/hv25_108.png: 384x640 5 cars, 11.4ms\n",
            "image 377/433 /content/datasets/images/test/hv25_156.png: 384x640 3 cars, 10.7ms\n",
            "image 378/433 /content/datasets/images/test/hv26_466.png: 352x640 1 car, 1 bus, 11.2ms\n",
            "image 379/433 /content/datasets/images/test/hv27_387.png: 384x640 1 car, 11.3ms\n",
            "image 380/433 /content/datasets/images/test/hv27_75.png: 384x640 1 car, 10.7ms\n",
            "image 381/433 /content/datasets/images/test/hv28_96.png: 384x640 2 cars, 1 bus, 10.7ms\n",
            "image 382/433 /content/datasets/images/test/hv29_142.png: 320x640 2 cars, 11.0ms\n",
            "image 383/433 /content/datasets/images/test/hv29_70.png: 320x640 5 cars, 1 bus, 10.4ms\n",
            "image 384/433 /content/datasets/images/test/hv36_601.png: 384x640 1 car, 11.3ms\n",
            "image 385/433 /content/datasets/images/test/hv36_675.png: 384x640 4 cars, 10.6ms\n",
            "image 386/433 /content/datasets/images/test/hv36_68.png: 384x640 3 cars, 10.6ms\n",
            "image 387/433 /content/datasets/images/test/hv37_1246.png: 352x640 12 cars, 1 bus, 11.2ms\n",
            "image 388/433 /content/datasets/images/test/hv37_1642.png: 352x640 5 cars, 10.5ms\n",
            "image 389/433 /content/datasets/images/test/hv37_650.png: 352x640 5 cars, 10.6ms\n",
            "image 390/433 /content/datasets/images/test/hv39_28.png: 384x640 8 cars, 1 bus, 11.3ms\n",
            "image 391/433 /content/datasets/images/test/hv39_679.png: 384x640 4 cars, 1 bus, 2 persons, 10.7ms\n",
            "image 392/433 /content/datasets/images/test/hv39_838.png: 384x640 2 cars, 1 bus, 1 person, 10.7ms\n",
            "image 393/433 /content/datasets/images/test/hv3_82.png: 384x640 2 persons, 10.7ms\n",
            "image 394/433 /content/datasets/images/test/hv40_155.png: 384x640 5 cars, 10.6ms\n",
            "image 395/433 /content/datasets/images/test/hv40_176.png: 384x640 7 cars, 1 bus, 10.4ms\n",
            "image 396/433 /content/datasets/images/test/hv40_307.png: 384x640 3 cars, 10.4ms\n",
            "image 397/433 /content/datasets/images/test/hv40_315.png: 384x640 6 cars, 10.4ms\n",
            "image 398/433 /content/datasets/images/test/hv40_87.png: 384x640 3 cars, 10.4ms\n",
            "image 399/433 /content/datasets/images/test/hv42_1071.png: 448x640 6 cars, 13.4ms\n",
            "image 400/433 /content/datasets/images/test/hv42_283.png: 448x640 4 cars, 12.6ms\n",
            "image 401/433 /content/datasets/images/test/hv42_336.png: 448x640 4 cars, 12.7ms\n",
            "image 402/433 /content/datasets/images/test/hv42_450.png: 448x640 2 cars, 1 person, 11.9ms\n",
            "image 403/433 /content/datasets/images/test/hv42_601.png: 448x640 1 car, 11.5ms\n",
            "image 404/433 /content/datasets/images/test/hv42_796.png: 448x640 1 car, 11.8ms\n",
            "image 405/433 /content/datasets/images/test/hv42_837.png: 448x640 5 cars, 11.5ms\n",
            "image 406/433 /content/datasets/images/test/hv42_885.png: 448x640 3 cars, 11.5ms\n",
            "image 407/433 /content/datasets/images/test/hv43_685.png: 384x640 3 cars, 2 buss, 12.1ms\n",
            "image 408/433 /content/datasets/images/test/hv43_724.png: 384x640 4 cars, 1 bus, 9.5ms\n",
            "image 409/433 /content/datasets/images/test/hv44_39.png: 384x640 10 cars, 10.4ms\n",
            "image 410/433 /content/datasets/images/test/hv47_1003.png: 480x640 1 car, 12.5ms\n",
            "image 411/433 /content/datasets/images/test/hv47_1167.png: 480x640 1 car, 11.6ms\n",
            "image 412/433 /content/datasets/images/test/hv47_566.png: 480x640 1 car, 1 bus, 11.6ms\n",
            "image 413/433 /content/datasets/images/test/hv47_729.png: 480x640 1 car, 12.3ms\n",
            "image 414/433 /content/datasets/images/test/hv47_856.png: 480x640 1 car, 11.7ms\n",
            "image 415/433 /content/datasets/images/test/hv48_200.png: 384x640 2 cars, 10.4ms\n",
            "image 416/433 /content/datasets/images/test/hv48_4.png: 384x640 6 cars, 1 bus, 1 person, 9.5ms\n",
            "image 417/433 /content/datasets/images/test/hv4_304.png: 512x640 7 cars, 12.6ms\n",
            "image 418/433 /content/datasets/images/test/hv50_304.png: 384x640 6 cars, 10.5ms\n",
            "image 419/433 /content/datasets/images/test/hv50_366.png: 384x640 6 cars, 9.5ms\n",
            "image 420/433 /content/datasets/images/test/hv50_384.png: 384x640 3 cars, 2 persons, 9.5ms\n",
            "image 421/433 /content/datasets/images/test/hv50_793.png: 384x640 5 cars, 2 buss, 9.5ms\n",
            "image 422/433 /content/datasets/images/test/hv50_81.png: 384x640 2 cars, 9.5ms\n",
            "image 423/433 /content/datasets/images/test/hv5_30.png: 384x640 3 cars, 1 bus, 9.5ms\n",
            "image 424/433 /content/datasets/images/test/hv5_34.png: 384x640 2 cars, 9.5ms\n",
            "image 425/433 /content/datasets/images/test/hv6_139.png: 384x640 6 cars, 3 buss, 10.0ms\n",
            "image 426/433 /content/datasets/images/test/hv6_147.png: 384x640 7 cars, 2 persons, 1 motorbike, 9.5ms\n",
            "image 427/433 /content/datasets/images/test/hv6_148.png: 384x640 8 cars, 2 buss, 2 persons, 1 motorbike, 9.5ms\n",
            "image 428/433 /content/datasets/images/test/hv6_20.png: 384x640 22 cars, 3 buss, 9.5ms\n",
            "image 429/433 /content/datasets/images/test/hv6_204.png: 384x640 11 persons, 9.5ms\n",
            "image 430/433 /content/datasets/images/test/hv6_24.png: 384x640 27 cars, 1 bus, 9.5ms\n",
            "image 431/433 /content/datasets/images/test/hv9_198.png: 448x640 3 cars, 15.8ms\n",
            "image 432/433 /content/datasets/images/test/hv9_21.png: 416x640 5 cars, 4 buss, 1 person, 12.2ms\n",
            "image 433/433 /content/datasets/images/test/hv9_36.png: 416x640 2 cars, 1 bus, 11.2ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1m/content/runs/detect\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ultralytics/ultralytics/runs/detect/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj5NCuGnYYcW",
        "outputId": "baa729ea-245b-4e94-b353-3b5e1d5158a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/ultralytics/ultralytics/runs/detect/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ultralytics/ultralytics/runs/detect/predict3/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2OqNXLnYw2k",
        "outputId": "a40acfb0-4d9f-40d2-d648-ee8e06e58dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/ultralytics/ultralytics/runs/detect/predict3/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JOISaLMeff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abf6971-d895-4cf9-b0e4-458e2a8fcea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No prediction images found! Check the file path.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "\n",
        "# Load the predicted images\n",
        "predicted_images = glob.glob(\"/content/ultralytics/ultralytics/runs/detect/predict3/*.jpg\")\n",
        "\n",
        "if len(predicted_images) == 0:\n",
        "    print(\"No prediction images found! Check the file path.\")\n",
        "else:\n",
        "    print(f\"Found {len(predicted_images)} predicted images. Displaying now...\")\n",
        "\n",
        "    # Display the first 5 images\n",
        "    for img_path in predicted_images[:5]:\n",
        "        display.display(Image.open(img_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deformable Convolution (C2f-DCN)"
      ],
      "metadata": {
        "id": "TCSR3upAQq1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.ops import DeformConv2d\n",
        "\n",
        "class C2fDCN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(C2fDCN, self).__init__()\n",
        "        self.conv_offset = nn.Conv2d(in_channels, 18, kernel_size=kernel_size, padding=1)\n",
        "        self.dcn = DeformConv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        offsets = self.conv_offset(x)\n",
        "        x = self.dcn(x, offsets)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GIzOI8PtQnsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Involution"
      ],
      "metadata": {
        "id": "OoGw4cBzuGp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Involution(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size=3):\n",
        "        super(Involution, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, groups=in_channels, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RKWyOc_RuGYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FasterNet"
      ],
      "metadata": {
        "id": "jteSdhdtuMS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FasterNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FasterNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "006-9NgwuN8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "S5 Attention"
      ],
      "metadata": {
        "id": "YXVn30u8uTcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class S5Attention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(S5Attention, self).__init__()\n",
        "        self.attn = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, kernel_size=1),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.attn(x)"
      ],
      "metadata": {
        "id": "AJb91RqWuVWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics --upgrade --quiet"
      ],
      "metadata": {
        "id": "Sy2dTprxuk93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "Ff3uOssCuzES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Integrate C2f-DCN, FasterNet, Involution, and S5Attention into YOLOv8"
      ],
      "metadata": {
        "id": "0CCfHizHyJtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics.models.yolo import Model\n",
        "\n",
        "class YOLOv8DF(Model):\n",
        "    def __init__(self, cfg=\"yolov8s.yaml\"):\n",
        "        super().__init__(cfg)\n",
        "\n",
        "        # Modify backbone\n",
        "        self.model[0] = C2fDCN(3, 64)  # Replace first layer with Deformable Convolution\n",
        "\n",
        "        # Modify feature extraction\n",
        "        self.model[3] = FasterNet(64, 128)\n",
        "        self.model[5] = Involution(128)\n",
        "\n",
        "        # Modify attention mechanism\n",
        "        self.model[-2] = S5Attention(256)\n",
        "\n",
        "        print(\"✅ YOLOv8-DF Model Initialized with Improvements\")\n",
        "\n",
        "# Load and print model summary\n",
        "model = YOLOv8DF()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "WyerTZ6OuZXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Improved YOLOv8-DF Model"
      ],
      "metadata": {
        "id": "qkLznqXayOX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov8_df.pt data=/content/datasets/data.yaml epochs=20 imgsz=640 batch=16 device=0\n"
      ],
      "metadata": {
        "id": "og64C4GtyDSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate Model Performance"
      ],
      "metadata": {
        "id": "znXVaMt7yRAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=val model=/content/runs/detect/train/weights/best.pt data=/content/datasets/data.yaml"
      ],
      "metadata": {
        "id": "WJm5-OaByTNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test YOLOv8-DF on Foggy Images"
      ],
      "metadata": {
        "id": "mvuv8jKayU34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/runs/detect/train/weights/best.pt source=/content/datasets/images/test save=True"
      ],
      "metadata": {
        "id": "XoyZDcGgyXEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Display Predictions from the Improved Model"
      ],
      "metadata": {
        "id": "37pvK3rKyZB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "\n",
        "# Load images from detect/\n",
        "predicted_images = glob.glob(\"/content/runs/detect/*.jpg\")\n",
        "\n",
        "if len(predicted_images) == 0:\n",
        "    print(\"❌ No prediction images found! Check YOLOv8 inference output.\")\n",
        "else:\n",
        "    print(f\"✅ Found {len(predicted_images)} predicted images. Displaying now...\")\n",
        "\n",
        "    # Display first 5 images\n",
        "    for img_path in predicted_images[:5]:\n",
        "        display.display(Image.open(img_path))"
      ],
      "metadata": {
        "id": "xFZqzeHfybMu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}